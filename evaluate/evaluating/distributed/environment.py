import os, time, pdb, functools
from typing import List
import multiprocessing as mp
from functools import partial
from contextlib import contextmanager
import sys
from enum import Enum, auto


_CURRENT_GROUP_KEY_ = "_CURRENT_GROUP_"

class _Marks(Enum):
    start = auto()
    sep = auto()
    end = auto()
    recover = auto()
class Marks(Enum):
    ckpt = auto()
    stop = auto()


def _assert_init(func):
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        assert Environment._manager is not None, \
            "You didn't initialize the environment, please add : 'mpenv.set_start_method()'."
        return func(*args, **kwargs)
    return wrapper


class _Group:
    @_assert_init
    def __init__(self, world_size: int):
        
        self.world_size = world_size

        self._comm_list = Environment._manager.list(
            [None for _ in range(world_size * world_size)]
        )

        self.barrier_lock = Environment._manager.Lock()
        self.barrier_count = Environment._manager.Value("i", 0)
        self.barrier_condition = Environment._manager.Condition(self.barrier_lock) 
        self.rank_queue = mp.Queue()
        self.registered_processes = Environment._manager.list()
        
        for rank in range(world_size): self.rank_queue.put(rank)

        self.rank_map = Environment._manager.dict()
        
        Environment._current_group = self
        Environment._group_count += 1
        Environment._process_count += world_size

    def barrier(self):
        with self.barrier_condition:
            self.barrier_count.value += 1 
            if self.barrier_count.value < self.world_size:
                self.barrier_condition.wait()
            else:
                self.barrier_count.value = 0
                self.barrier_condition.notify_all()



class Environment:
    _indent: int = 0
    _group_count: int = 0
    _process_count: int = 0
    _current_group: _Group = None

    _manager = None
    

    @classmethod
    def set_start_method(cls, method: str = "fork", force: bool = False):
        mp.set_start_method(method = method, force = force)
        cls._init_manager()
    
    @classmethod
    def get_start_method(cls, allow_none: bool = False) -> str:
        return mp.get_start_method(allow_none = allow_none)

    @classmethod
    def _init_manager(cls):
        if cls._manager is None:
            cls._manager = mp.Manager()

    @classmethod
    def _active_pid(cls):
        return set(p.pid for p in mp.active_children())

    @classmethod
    def _init_group(cls, world_size):
        return _Group(world_size = world_size)

    @classmethod
    @contextmanager
    def add_process_group(cls, world_size):

        if cls._indent:
            yield
            raise RuntimeError("Nested calling `with add_process_group(wolrd_size)` is not allowed!")
        
        cls._indent += 1
        
        group = cls._init_group(world_size = world_size)
        enter_pids = cls._active_pid()

        yield

        exit_pids  = cls._active_pid()
        this_pids = set(group.registered_processes) | (exit_pids - enter_pids)
        

        if len(this_pids) < group.world_size:
            raise ValueError("You set a world_size larger than the total number of "
                        "sub-processes that join the process group.")
            
        start_wait = time.time()
        while group.rank_queue.qsize(): # waiting all ranks to be allocated
            if time.time() - start_wait > group.world_size  * 10:
                raise ValueError("You set a world_size larger than the total number of "
                            "sub-processes that join the process group.")
            
        cls._indent -= 1
        cls._current_group = None

    @classmethod
    def start_process_group(cls, processes: List[mp.Process | dict]):
        if cls._indent:
            raise RuntimeError("Calling `start_process_group(processes)` in "
                               "`with add_process_group(world_size)` is not allowed!")
        
        group = cls._init_group(world_size = len(processes))
        enter_pids = cls._active_pid()

        for process in processes: 
            if isinstance(process, dict): process = mp.Process(**process)
            process.start()

        exit_pids = cls._active_pid()
        this_pids = set(group.registered_processes) | (exit_pids - enter_pids)

        if len(this_pids) < group.world_size:
            raise ValueError("You set a world_size larger than the total number of "
                        "sub-processes that join the process group.")

        start_wait = time.time()
        while group.rank_queue.qsize(): # waiting all ranks to be allocated
            if time.time() - start_wait > group.world_size/10:
                raise ValueError("You set a world_size larger than the total number of "
                            "sub-processes that join the process group.")
    
    @classmethod
    def need_rank(cls, func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            pid = os.getpid()
            cls._current_group = kwargs.pop(
                _CURRENT_GROUP_KEY_, cls._current_group
            )
            if cls._current_group is None:
                raise RuntimeError("You aimed to allocate rank for each process, but didn't "
                                   "run `with Environment.add_process_group(world_size)`.")
            group = cls._current_group
            group.registered_processes.append(pid)

            if group.rank_queue.qsize() == 0:
                raise ValueError("You set a world_size less than the total number of "
                                 "sub-processes that join the process group.")
            
            group.rank_map[pid] = group.rank_queue.get()
            
            ret = func(*args, **kwargs)

            return ret
        return wrapper
    
    @classmethod
    def wrap(cls, target):
        if cls.get_start_method() == "spawn":
            target = partial(target, **{_CURRENT_GROUP_KEY_ : cls._current_group})
        return target

    @classmethod
    def Process(cls, target, args):
        target = cls.wrap(target)
        process = mp.Process(target = target, 
                             args = args)

        return process
    

    @classmethod
    @_assert_init
    def set_pdb_trace(cls, rank: int = None):
        if rank !=None and cls.get_rank()!=rank: 
            return
        sys.stdin = open(0)  
        pdb.set_trace()
    
    
    @classmethod
    def getpid(cls):
        return os.getpid()
    
    @classmethod
    def getppid(cls):
        return os.getppid()
    
    @classmethod
    def getgid(cls):
        return cls._group_count - 1
    
    @classmethod
    def get_world_size(cls):
        '''run in child processes'''
        return cls._current_group.world_size

    @classmethod
    def get_rank(cls):
        '''run in child processes'''
        return cls._current_group.rank_map[os.getpid()]
    
    @classmethod
    def get_global_rank(cls):
        return cls._process_count - cls._current_group.world_size + cls.get_rank()
    
    @classmethod
    def barrier(cls):
        cls._current_group.barrier()
    

    
    @classmethod
    def gather(cls, obj, dst: int = 0):
        cls._current_group._comm_list[cls.get_rank()] = obj
        cls.barrier()
        gathered = []
        if dst == cls.get_rank():
            gathered.extend(list(cls._current_group._comm_list[: cls.get_world_size()]))
            del cls._current_group._comm_list[-cls.get_world_size(): ]
            cls._current_group._comm_list.extend([None] * cls.get_world_size())
        return gathered
    
    @classmethod
    def all_gather(cls, obj):
        cls._current_group._comm_list[cls.get_rank()] = obj
        cls.barrier()
        gathered = list(cls._current_group._comm_list[:  cls.get_world_size()])
        cls.barrier()
        del cls._current_group._comm_list[-cls.get_rank():]
        cls._current_group._comm_list.extend([None] * cls.get_world_size())
        cls.barrier()
        return gathered

    @classmethod
    def set_cuda_visible_devices(cls, devices: str):
        os.environ["CUDA_VISIBLE_DEVICES"] = devices

    @classmethod
    def get_cuda_visible_devices(cls):
        return os.environ["CUDA_VISIBLE_DEVICES"]
    
    @classmethod
    def set_cuda_alloc_conf(cls, expandable_segments: bool = True):
        os.environ["PYTORCH_CUDA_ALLOC_CONF"] = f"expandable_segments:{expandable_segments}"

    @classmethod
    def set_tokenizers_parallelism(cls, enable: bool = True):
        os.environ["TOKENIZERS_PARALLELISM"] = str(enable).lower()

    @classmethod
    def set_triton_debug(cls, enable: bool = True):
        os.environ["TRITON_DEBUG"] = str(int(enable))

    @classmethod
    def set_cuda_launch_blocking(cls, enable: bool = True):
        os.environ["CUDA_LAUNCH_BLOCKING"] = str(int(enable))

    @classmethod
    def set_torch_use_cuda_dsa(cls, enable: bool = True):
        os.environ["TORCH_USE_CUDA_DSA"] = str(int(enable))

    @classmethod
    def set_vllm_enable_v1_multiprocessing(cls, enable: bool = False):
        os.environ["VLLM_ENABLE_V1_MULTIPROCESSING"] = str(int(enable))

    @classmethod
    def get_cuda_devices_count(cls):
        import pynvml
        pynvml.nvmlInit()
        count = pynvml.nvmlDeviceGetCount()
        pynvml.nvmlShutdown()
        return count
    
    @classmethod
    def get_cuda_memory_info(cls, device: int = 0):
        '''return total, used, free'''
        import pynvml
        pynvml.nvmlInit()
        handle = pynvml.nvmlDeviceGetHandleByIndex(device)  # 0 表示第 0 块 GPU
        info = pynvml.nvmlDeviceGetMemoryInfo(handle)
        total, used, free = \
            info.total//1024**2, info.used//1024**2, info.free//1024**2
        pynvml.nvmlShutdown()

        return dict(
            total = total,
            used = used,
            free = free,
            used_ratio =  used/total,
        )

    @classmethod
    def get_idle_gpus(cls):
        return [
            i for i in range(cls.get_cuda_devices_count()) \
            if cls.get_cuda_memory_info(i)["used_ratio"] < 1/100
        ]
